{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Introduction**\n",
    "\n",
    "**2. A brief explanation of the dataset**\n",
    "\n",
    "**3. Data Dictionary**\n",
    "\n",
    "**4. Data Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Import Libraries\n",
    "\n",
    "4.2 Import Dataset\n",
    "\n",
    "4.3 Data Description\n",
    "\n",
    "4.4 Vizualization\n",
    "\n",
    "4.5 Classifier Models (LogisticRegression, KNN, Decision Tree, Random Forest, SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief explanation of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Information\n",
    "\n",
    "This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary\n",
    "\n",
    "**family_history_with_overweight:** Feature, Binary, \" Has a family member suffered or suffers from overweight? \"\n",
    "\n",
    "**FAVC :** Feature, Binary, \" Do you eat high caloric food frequently? \"\n",
    "\n",
    "**FCVC :** Feature, Integer, \" Do you usually eat vegetables in your meals? \"\n",
    "\n",
    "**NCP :** Feature, Continuous, \" How many main meals do you have daily? \"\n",
    "\n",
    "**CAEC :** Feature, Categorical, \" Do you eat any food between meals? \"\n",
    "\n",
    "**SMOKE :** Feature, Binary, \" Do you smoke? \"\n",
    "\n",
    "**CH2O:** Feature, Continuous, \" How much water do you drink daily? \"\n",
    "\n",
    "**SCC:** Feature, Binary, \" Do you monitor the calories you eat daily? \"\n",
    "\n",
    "**FAF:** Feature, Continuous, \" How often do you have physical activity? \"\n",
    "\n",
    "**TUE :** Feature, Integer, \" How much time do you use technological devices such as cell phone, videogames, television, computer and others? \"\n",
    "\n",
    "**CALC :** Feature, Categorical, \" How often do you drink alcohol? \"\n",
    "\n",
    "**MTRANS :** Feature, Categorical, \" Which transportation do you usually use? \"\n",
    "\n",
    "**NObeyesdad :** Target, Categorical, \"Obesity level\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: Questions of the survey\n",
    "\n",
    "| **Questions**                                                                                                   | **Possible Answers**                                                 | **Type**    |\n",
    "| --------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- | ----------- | ------ |\n",
    "| What is your gender?                                                                                            | Female, Male                                                         | Categorical |\n",
    "| What is your age?                                                                                               | From 14 years old to 61 or more                                      | Continuous  |\n",
    "| What is your height?                                                                                            | From 1.45 Mts to 1.98 Mts                                            | Continuous  |\n",
    "| What is your weight?                                                                                            | From 39 Kg to 173 Kg                                                 | Continuous  |\n",
    "| Has a family member suffered or suffers from overweight?                                                        | yes, no                                                              | Binary      |\n",
    "| Do you eat high caloric food frequently?                                                                        | yes, no                                                              | Binary      |\n",
    "| Do you usually eat vegetables in your meals?                                                                    | 1 = Never, 2 = Sometimes, 3 = Always                                 | Integer     |\n",
    "| How many main meals do you have daily?                                                                          | Between 1 and 4                                                      | Continuous  |\n",
    "| Do you eat any food between meals?                                                                              | no, Sometimes, Frequently, Always                                    | Categorical |\n",
    "| Do you smoke?                                                                                                   | yes, no                                                              | Binary      |\n",
    "| How much water do you drink daily?                                                                              | 1 = Less than a liter, 2 = Between 1 and 2 L, 3 = More than 2 L      | Continuous  |\n",
    "| Do you monitor the calories you eat daily?                                                                      | yes, no                                                              |             | Binary |\n",
    "| How often do you have physical activity?                                                                        | 0 = I do not have, 1 = 1 or 2 days, 2 = 2 or 4 days, 3 = 4 or 5 days | Continuous  |\n",
    "| How much time do you use technological devices such as cell phone, videogames, television, computer and others? | 0 = 0–2 hours, 1 = 3–5 hours, 2 = More than 5 hours                  | Integer     |\n",
    "| How often do you drink alcohol?                                                                                 | I do not drink, Sometimes, Frequently, Always                        | Categorical |\n",
    "| Which transportation do you usually use?                                                                        | Automobile, Motorbike, Bike, Public Transportation, Walking          | Categorical |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# fetch dataset\n",
    "dataset = fetch_ucirepo(\n",
    "    id=544)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "\n",
    "# metadata\n",
    "print(dataset.metadata)\n",
    "\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this project we have 2111 samples with 16 features and one target (NObeyesdad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Gender', 'CALC', 'FAVC', 'SCC',\n",
    "                        'SMOKE', 'family_history_with_overweight', 'CAEC', 'MTRANS']\n",
    "\n",
    "\n",
    "continuous_features = ['Age', 'Height', 'Weight',\n",
    "                       'FCVC', \"NCP\", 'CH2O', 'FAF', 'TUE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pie chart of target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = df['NObeyesdad'].value_counts()\n",
    "target_unique = df['NObeyesdad'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.pie(values=target_count, names=target_unique, color_discrete_sequence=px.colors.qualitative.Pastel1,\n",
    "             title=\"the number of people related to each type of obesity level\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating new dataframes targeting the targets in obesity level with the same type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obesity type I,II,III\n",
    "df_ot = df[df[\"NObeyesdad\"] == 'Obesity_Type_I']\n",
    "\n",
    "\n",
    "df_ot2 = df[df[\"NObeyesdad\"] == 'Obesity_Type_II']\n",
    "\n",
    "\n",
    "df_ot3 = df[df[\"NObeyesdad\"] == 'Obesity_Type_III']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frem of Obesity_Type I, II, III\n",
    "df_ot_final = pd.concat([df_ot, df_ot2, df_ot3])\n",
    "df_ot_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over weight type I,II\n",
    "df_ow = df[df[\"NObeyesdad\"] == 'Overweight_Level_I']\n",
    "\n",
    "df_ow2 = df[df[\"NObeyesdad\"] == 'Overweight_Level_II']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frem of Over_weight_Type I, II\n",
    "df_ow_final = pd.concat([df_ow, df_ow2])\n",
    "df_ow_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Weight\n",
    "df_n = df[df[\"NObeyesdad\"] == 'Normal_Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insufficient Weight\n",
    "df_In = df[df[\"NObeyesdad\"] == 'Insufficient_Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 different dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Gender', 'CALC', 'FAVC', 'SCC',\n",
    "                        'SMOKE', 'family_history_with_overweight', 'CAEC', 'MTRANS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of gender across different obesity levels:\n",
    "\n",
    "- Gender can be a significant factor in obesity patterns\n",
    "- Understanding gender distribution helps identify potential biases in the dataset\n",
    "- It provides insights into whether certain obesity levels are more prevalent in specific genders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='Gender', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs Gender')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='Gender', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs Gender')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs Gender')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='CALC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs CALC')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='CALC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs CALC')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs CALC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='FAVC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs FAVC')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='FAVC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs FAVC')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs FAVC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='SCC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs SCC')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='SCC', hue='NObeyesdad',\n",
    "                 palette=\"turbo\", ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs SCC')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs SCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOKE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='SMOKE', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs SMOKE')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='SMOKE', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs SMOKE')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs SMOKE')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# family_history_with_overweight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='family_history_with_overweight',\n",
    "                 hue='NObeyesdad', palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs family_history_with_overweight')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='family_history_with_overweight',\n",
    "                 hue='NObeyesdad', palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs family_history_with_overweight')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs family_history_with_overweight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAEC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='CAEC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs CAEC')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='CAEC', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs CAEC')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs CAEC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTRANS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 8), nrows=2, ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.histplot(data=data_list[i], x='MTRANS', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 0], multiple='stack')\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs MTRANS')\n",
    "\n",
    "    sns.histplot(data=data_list[i+2], x='MTRANS', hue='NObeyesdad',\n",
    "                 palette='turbo', ax=axes[i, 1], multiple='stack')\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs MTRANS')\n",
    "\n",
    "fig.suptitle('Obesity_levels vs MTRANS')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sunburst chart (categorical features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "\n",
    "\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "\n",
    "\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'Gender'], color='Gender',\n",
    "\n",
    "\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "\n",
    "\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'Gender'], color='Gender',\n",
    "\n",
    "\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "\n",
    "\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'Gender'], color='Gender',\n",
    "\n",
    "\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "\n",
    "\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'Gender'], color='Gender',\n",
    "\n",
    "\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "\n",
    "\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800,\n",
    "                  title_text=(\"Obesity levels vs Gender\"))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'CALC'], color='CALC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'CALC'], color='CALC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'CALC'], color='CALC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'CALC'], color='CALC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800, title_text=(\"Obesity levels vs CALC\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'FAVC'], color='FAVC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'FAVC'], color='FAVC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'FAVC'], color='FAVC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'FAVC'], color='FAVC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800, title_text=(\"Obesity levels vs FAVC\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'SCC'], color='SCC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'SCC'], color='SCC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'SCC'], color='SCC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'SCC'], color='SCC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800, title_text=(\"Obesity levels vs SCC\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOKE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'SMOKE'], color='SMOKE',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'SMOKE'], color='SMOKE',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'SMOKE'], color='SMOKE',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'SMOKE'], color='SMOKE',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800,\n",
    "                  title_text=(\"Obesity levels vs SMOKE\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAEC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'CAEC'], color='CAEC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'CAEC'], color='CAEC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'CAEC'], color='CAEC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'CAEC'], color='CAEC',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800, title_text=(\"Obesity levels vs CAEC\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTRANS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}], [{\"type\": \"sunburst\"}, {\"type\": \"sunburst\"}]],\n",
    "                    subplot_titles=[\"Obesity_Types vs family_history\", \"Over_weight vs family_history\",\n",
    "                                    \"Normal_weight vs family_history\", \"Insufficient_Weight vs family_history\"],\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "\n",
    "figaux = px.sunburst(df_ot_final, path=['NObeyesdad', 'MTRANS'], color='MTRANS',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "figaux = px.sunburst(df_ow_final, path=['NObeyesdad', 'MTRANS'], color='MTRANS',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=1, col=2)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_In, path=['NObeyesdad', 'MTRANS'], color='MTRANS',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=1)\n",
    "\n",
    "#############################################\n",
    "\n",
    "figaux = px.sunburst(df_n, path=['NObeyesdad', 'MTRANS'], color='MTRANS',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel1)\n",
    "fig.add_trace(figaux.data[0], row=2, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=800,\n",
    "                  title_text=(\"Obesity levels vs MTRANS\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['Age', 'Height', 'Weight',\n",
    "                       'FCVC', \"NCP\", 'CH2O', 'FAF', 'TUE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"Age\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs Age')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"Age\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs Age')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs Age')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obesity type III focus between ~18 and 30 years old\n",
    "2. Most people of normal weight are young, and this group shrinks with age\n",
    "3. Overweight begins to appear in young adults and can continue into middle age.\n",
    "4. Underweight is more common in adolescents and young adults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"Height\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs Height')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"Height\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs Height')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Being overweight is not directly associated with a specific height, although it tends to be concentrated among people of average height.\n",
    "4. Underweight is not determined by height.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"Weight\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs Weight')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"Weight\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs Weight')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs Weight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"FCVC\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs FCVC')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"FCVC\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs FCVC')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs FCVC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"NCP\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs NCP')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"NCP\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs NCP')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs NCP')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH2O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"CH2O\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs CH2O')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"CH2O\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs CH2O')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs CH2O')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"FAF\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs FAF')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"FAF\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs FAF')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs FAF')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [df_ot_final, df_ow_final, df_n, df_In]\n",
    "data_name = [\"obesity_type\", \"over_weight_type\",\n",
    "             \"normal\", \"Insufficient_Weight\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 0], data=data_list[i],\n",
    "                x=\"TUE\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 0].set_title(f'{data_name[i]} vs TUE')\n",
    "\n",
    "    sns.kdeplot(ax=axes[i, 1], data=data_list[i+2],\n",
    "                x=\"TUE\", hue=\"NObeyesdad\", fill=True)\n",
    "    axes[i, 1].set_title(f'{data_name[i+2]} vs TUE')\n",
    "\n",
    "\n",
    "fig.suptitle('Obesity_levels vs TUE')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## manual feature encoding ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['NObeyesdad'] == 'Normal_Weight', 'NObeyesdad'] = 2\n",
    "df1.loc[df1['NObeyesdad'] == 'Overweight_Level_I', 'NObeyesdad'] = 3\n",
    "df1.loc[df1['NObeyesdad'] == 'Overweight_Level_II', 'NObeyesdad'] = 4\n",
    "df1.loc[df1['NObeyesdad'] == 'Obesity_Type_I', 'NObeyesdad'] = 5\n",
    "df1.loc[df1['NObeyesdad'] == 'Insufficient_Weight', 'NObeyesdad'] = 6\n",
    "df1.loc[df1['NObeyesdad'] == 'Obesity_Type_II', 'NObeyesdad'] = 7\n",
    "df1.loc[df1['NObeyesdad'] == 'Obesity_Type_III', 'NObeyesdad'] = 8\n",
    "\n",
    "###################### data to number #################\n",
    "\n",
    "# Gender\n",
    "\n",
    "df1.loc[df1['Gender'] == 'Female', 'Gender'] = 2\n",
    "df1.loc[df1['Gender'] == 'Male', 'Gender'] = 3\n",
    "\n",
    "# family_history_with_overweight\n",
    "\n",
    "df1.loc[df1['family_history_with_overweight'] ==\n",
    "        'no', 'family_history_with_overweight'] = 2\n",
    "df1.loc[df1['family_history_with_overweight'] ==\n",
    "        'yes', 'family_history_with_overweight'] = 3\n",
    "\n",
    "# FAVC\n",
    "\n",
    "df1.loc[df1['FAVC'] == 'no', 'FAVC'] = 2\n",
    "df1.loc[df1['FAVC'] == 'yes', 'FAVC'] = 3\n",
    "\n",
    "# CAEC\n",
    "\n",
    "df1.loc[df1['CAEC'] == 'no', 'CAEC'] = 2\n",
    "df1.loc[df1['CAEC'] == 'Sometimes', 'CAEC'] = 3\n",
    "df1.loc[df1['CAEC'] == 'Frequently', 'CAEC'] = 4\n",
    "df1.loc[df1['CAEC'] == 'Always', 'CAEC'] = 5\n",
    "\n",
    "# SMOKE\n",
    "\n",
    "df1.loc[df1['SMOKE'] == 'no', 'SMOKE'] = 2\n",
    "df1.loc[df1['SMOKE'] == 'yes', 'SMOKE'] = 3\n",
    "\n",
    "# SCC\n",
    "\n",
    "df1.loc[df1['SCC'] == 'no', 'SCC'] = 2\n",
    "df1.loc[df1['SCC'] == 'yes', 'SCC'] = 3\n",
    "\n",
    "# CALC\n",
    "\n",
    "df1.loc[df1['CALC'] == 'no', 'CALC'] = 2\n",
    "df1.loc[df1['CALC'] == 'Sometimes', 'CALC'] = 3\n",
    "df1.loc[df1['CALC'] == 'Frequently', 'CALC'] = 4\n",
    "df1.loc[df1['CALC'] == 'Always', 'CALC'] = 5\n",
    "\n",
    "# MTRANS\n",
    "\n",
    "df1.loc[df1['MTRANS'] == 'Automobile', 'MTRANS'] = 2\n",
    "df1.loc[df1['MTRANS'] == 'Motorbike', 'MTRANS'] = 3\n",
    "df1.loc[df1['MTRANS'] == 'Bike', 'MTRANS'] = 4\n",
    "df1.loc[df1['MTRANS'] == 'Public_Transportation', 'MTRANS'] = 5\n",
    "df1.loc[df1['MTRANS'] == 'Walking', 'MTRANS'] = 6\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df1 = df1.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.heatmap(df1.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title('The correlation among features', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to heat map it can be seen that there is strong correlation between weight and obesity levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop(columns=[\"NObeyesdad\"])\n",
    "y = df1[\"NObeyesdad\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def LogReg(x, y, test_size, solver_list):\n",
    "\n",
    "    df_evaluation = pd.DataFrame()\n",
    "\n",
    "    ########################### normalizing data  ------------->  StandardScaler ###################################\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    ########################## logistic model ####################################\n",
    "\n",
    "    c_list = [0.1, 0.2, 0.4, 0.5, 1, 2, 4, 5, 10, 20, 50, 100, 400]\n",
    "\n",
    "    for c in c_list:\n",
    "\n",
    "        for s in solver_list:\n",
    "\n",
    "            logreg = LogisticRegression(\n",
    "                solver=s, penalty='l2', C=c, class_weight='balanced')\n",
    "\n",
    "            logreg.fit(x_train_scaled, y_train.ravel())\n",
    "\n",
    "            y_pred = logreg.predict(x_test_scaled)\n",
    "\n",
    "            #####################\n",
    "\n",
    "            x_norm = scaler.transform(x)\n",
    "\n",
    "            dict = {'Test_size': test_size, \"acc\": metrics.accuracy_score(\n",
    "                y_test, y_pred), \"c\": c, \"solver\": s, \"score\": logreg.score(x_norm, y)}\n",
    "\n",
    "            df_entry = pd.DataFrame([dict])  # Convert dictionary to DataFrame\n",
    "\n",
    "            # Concatenate DataFrames\n",
    "            df_evaluation = pd.concat(\n",
    "                [df_evaluation, df_entry], ignore_index=True)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test, y_pred, df_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test, y_pred, df_evaluation = LogReg(\n",
    "    x, y, .25, ['newton-cg', 'sag', 'saga', 'lbfgs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: gray' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Logistic Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÓDIGO CORREGIDO:\n",
    "best_logreg_model = LogisticRegression(\n",
    "    solver='newton-cg',\n",
    "    penalty='l2',\n",
    "    C=400,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "best_logreg_model.fit(x_train_scaled, y_train.values.ravel())  # ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "confusion_matrix(y, best_logreg_model.predict(x_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, best_logreg_model.predict(x_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = ['cityblock', 'euclidean',\n",
    "               'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
    "\n",
    "\n",
    "p_list = [1, 2]\n",
    "\n",
    "n_neighbors_list = range(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(x, y, test_size, p):\n",
    "    training_acc = []\n",
    "    test_acc = []\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    df_evaluation = pd.DataFrame()\n",
    "\n",
    "    ########################### normalizing data  ------------->  StandardScaler ###################################\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    ########################### knn model ###################################\n",
    "\n",
    "    for k in n_neighbors_list:\n",
    "\n",
    "        for metric in metric_list:\n",
    "\n",
    "            knn_model = KNeighborsClassifier(k, p=p, metric=metric, n_jobs=-1)\n",
    "            # ✅ Corregido: DataFrame → array\n",
    "            knn_model.fit(x_train_scaled, y_train.values.ravel())\n",
    "            y_pred = knn_model.predict(x_test_scaled)\n",
    "\n",
    "            training_acc.append(knn_model.score(x_train_scaled, y_train))\n",
    "            test_acc.append(knn_model.score(x_test_scaled, y_test))\n",
    "\n",
    "            x_norm = scaler.transform(x)\n",
    "\n",
    "            dict = {'Test_size': test_size, \"acc\": metrics.accuracy_score(\n",
    "                y_test, y_pred), \"metric\": metric, \"p\": p, \"n_neighbor\": k, \"score\": knn_model.score(x_norm, y)}\n",
    "\n",
    "            df_entry = pd.DataFrame([dict])  # Convert dictionary to DataFrame\n",
    "            # Concatenate DataFrames\n",
    "            df_evaluation = pd.concat(\n",
    "                [df_evaluation, df_entry], ignore_index=True)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation = KNN(\n",
    "    x, y, 0.1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~ 1 minute**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best KNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_model = KNeighborsClassifier(1, p=1, metric='cityblock', n_jobs=-1)\n",
    "best_knn_model.fit(x_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = best_knn_model.score(x_norm, y)\n",
    "knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, best_knn_model.predict(x_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, best_knn_model.predict(x_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def Decision_Tree(x, y, test_size, max_depth_list):\n",
    "    training_acc, test_acc = [], []\n",
    "    criterion_list = ['entropy', 'gini']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=0)\n",
    "    df_evaluation = pd.DataFrame()\n",
    "    ########################### normalizing data  ------------->  StandardScaler ###################################\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    ########################### Decision_Tree model ###################################\n",
    "\n",
    "    for criterion in (criterion_list):\n",
    "\n",
    "        for m in max_depth_list:\n",
    "\n",
    "            tree_model = DecisionTreeClassifier(\n",
    "                criterion=criterion, max_depth=m, random_state=0)\n",
    "\n",
    "            tree_model.fit(x_train_scaled, y_train.values.ravel())\n",
    "            y_pred = tree_model.predict(x_test_scaled)\n",
    "\n",
    "            training_acc.append(tree_model.score(x_train_scaled, y_train))\n",
    "            test_acc.append(tree_model.score(x_test_scaled, y_test))\n",
    "\n",
    "            x_norm = scaler.transform(x)\n",
    "\n",
    "            dict = {'Test_size': test_size, \"acc\": metrics.accuracy_score(\n",
    "                y_test, y_pred), \"criterion\": criterion, \"max_depth\": m, \"score\": tree_model.score(x_norm, y)}\n",
    "\n",
    "            df_entry = pd.DataFrame([dict])  # Convert dictionary to DataFrame\n",
    "\n",
    "            # Concatenate DataFrames\n",
    "            df_evaluation = pd.concat(\n",
    "                [df_evaluation, df_entry], ignore_index=True)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation = Decision_Tree(\n",
    "    x, y, 0.1, range(2, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_DT_model = DecisionTreeClassifier(\n",
    "    criterion='entropy', max_depth=9, random_state=0)\n",
    "\n",
    "\n",
    "best_DT_model.fit(x_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_acc = best_DT_model.score(x_norm, y)\n",
    "DT_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, best_DT_model.predict(x_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, best_DT_model.predict(x_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest(x, y, test_size, max_depth_list):\n",
    "    training_acc, test_acc = [], []\n",
    "    criterion_list = ['entropy', 'gini']\n",
    "    estimator_list = range(10, 101)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    df_evaluation = pd.DataFrame()\n",
    "    ########################### normalizing data  ------------->  StandardScaler ###################################\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    ########################### Rf model ###################################\n",
    "\n",
    "    for s in estimator_list:\n",
    "\n",
    "        for m in max_depth_list:\n",
    "\n",
    "            for criterion in (criterion_list):\n",
    "\n",
    "                Rf_model = RandomForestClassifier(\n",
    "                    n_estimators=s, max_depth=m, criterion=criterion, random_state=0)\n",
    "                Rf_model.fit(x_train_scaled, y_train.values.ravel())\n",
    "                y_pred = Rf_model.predict(x_test_scaled)\n",
    "\n",
    "                training_acc.append(Rf_model.score(x_train_scaled, y_train))\n",
    "                test_acc.append(Rf_model.score(x_test_scaled, y_test))\n",
    "\n",
    "                x_norm = scaler.transform(x)\n",
    "\n",
    "                dict = {'Test_size': test_size, \"acc\": metrics.accuracy_score(y_test, y_pred),\n",
    "                        \"n_estimator\": s, \"criterion\": criterion, \"max_depth\": m,\n",
    "                        \"score\": Rf_model.score(x_norm, y)}\n",
    "\n",
    "                # Convert dictionary to DataFrame\n",
    "                df_entry = pd.DataFrame([dict])\n",
    "                # Concatenate DataFrames\n",
    "                df_evaluation = pd.concat(\n",
    "                    [df_evaluation, df_entry], ignore_index=True)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation = Random_Forest(\n",
    "    x, y, 0.1, range(2, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~ 42 minutes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF_model = RandomForestClassifier(\n",
    "    n_estimators=46, max_depth=15, criterion='entropy', random_state=0)\n",
    "\n",
    "best_RF_model.fit(x_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_acc = best_RF_model.score(x_norm, y)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, best_RF_model.predict(x_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, best_RF_model.predict(x_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def svm_model(x, y, test_size):\n",
    "    training_acc, test_acc = [], []\n",
    "    kernel_list = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    penalty_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=0)\n",
    "    df_evaluation1 = pd.DataFrame()\n",
    "\n",
    "    ########################### normalizing data  ------------->  StandardScaler ###################################\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    ########################### SVM ###################################\n",
    "\n",
    "    for kernel in kernel_list:\n",
    "\n",
    "        for c in penalty_list:\n",
    "\n",
    "            svm_model = SVC(kernel=kernel, C=c)\n",
    "            svm_model.fit(x_train_scaled, y_train.values.ravel())\n",
    "            y_pred = svm_model.predict(x_test_scaled)\n",
    "            training_acc.append(svm_model.score(x_train_scaled, y_train))\n",
    "            test_acc.append(svm_model.score(x_test_scaled, y_test))\n",
    "            x_norm = scaler.transform(x)\n",
    "            dict = {'Test_size': test_size, \"acc\": metrics.accuracy_score(y_test, y_pred),\n",
    "                    \"penalty\": c, \"kernel\": kernel, \"score\": svm_model.score(x_norm, y)}\n",
    "\n",
    "            df_entry = pd.DataFrame([dict])  # Convert dictionary to DataFrame\n",
    "            # Concatenate DataFrames\n",
    "            df_evaluation1 = pd.concat(\n",
    "                [df_evaluation1, df_entry], ignore_index=True)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train, x_test, y_train, y_test, training_acc, test_acc, y_pred, df_evaluation1 = svm_model(\n",
    "    x, y, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏆 CONFIGS BY KERNEL\".center(80))\n",
    "\n",
    "best_by_kernel = df_evaluation1.loc[df_evaluation1.groupby('kernel')[\n",
    "    'acc'].idxmax()]\n",
    "best_by_kernel_sorted = best_by_kernel.sort_values('acc', ascending=False)\n",
    "\n",
    "print(f\"\\n{'Kernel':<12} {'C (Penalty)':<15} {'Accuracy':<12} {'Score Total':<12}\")\n",
    "print(\"-\"*80)\n",
    "for idx, row in best_by_kernel_sorted.iterrows():\n",
    "    print(\n",
    "        f\"{row['kernel']:<12} {row['penalty']:<15.2f} {row['acc']:<12.4f} {row['score']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "best_overall = df_evaluation1.loc[df_evaluation1['acc'].idxmax()]\n",
    "print(f\"BEST GENERAL CONFIG:\")\n",
    "print(f\"   Kernel: {best_overall['kernel']}\")\n",
    "print(f\"   C (Penalty): {best_overall['penalty']}\")\n",
    "print(f\"   Accuracy: {best_overall['acc']:.4f}\")\n",
    "print(f\"   Total: {best_overall['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Curves of accuracy vs penalty (C) for each kernel\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1: All curves\n",
    "plt.subplot(1, 2, 1)\n",
    "for kernel in df_evaluation1['kernel'].unique():\n",
    "    kernel_data = df_evaluation1[df_evaluation1['kernel'] == kernel].sort_values(\n",
    "        'penalty')\n",
    "    plt.plot(kernel_data['penalty'], kernel_data['acc'],\n",
    "             marker='o', label=kernel, linewidth=2, markersize=6)\n",
    "\n",
    "plt.title('Accuracy vs Penalty (C) by Kernel', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Penalty (C)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(title='Kernel', fontsize=10)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xlim([df_evaluation1['penalty'].min() - 0.05,\n",
    "         df_evaluation1['penalty'].max() + 0.05])\n",
    "\n",
    "# Subplot 2: Heatmap of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "pivot_table = df_evaluation1.pivot_table(\n",
    "    values='acc', index='kernel', columns='penalty')\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='RdYlGn', cbar_kws={'label': 'Accuracy'},\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "plt.title('Heatmap: Accuracy Kernel & Penalty',\n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Penalty (C)', fontsize=12)\n",
    "plt.ylabel('Kernel', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Entrenar el mejor modelo encontrado\n",
    "best_config = df_evaluation1.loc[df_evaluation1['acc'].idxmax()]\n",
    "print(\n",
    "    f\"🏆 Training best model: kernel={best_config['kernel']}, C={best_config['penalty']}\\n\")\n",
    "\n",
    "# Re-train with the best configuration\n",
    "scaler_best = StandardScaler()\n",
    "x_train_scaled_best = scaler_best.fit_transform(x_train)\n",
    "x_test_scaled_best = scaler_best.transform(x_test)\n",
    "\n",
    "best_model = SVC(kernel=best_config['kernel'], C=best_config['penalty'])\n",
    "best_model.fit(x_train_scaled_best, y_train.values.ravel())\n",
    "y_pred_best = best_model.predict(x_test_scaled_best)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Conteo'},\n",
    "            linewidths=1, linecolor='gray', square=True)\n",
    "plt.title(f'Confusion Matrix\\nKernel: {best_config[\"kernel\"]}, C: {best_config[\"penalty\"]}, Accuracy: {best_config[\"acc\"]:.4f}',\n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Real Class', fontsize=12)\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"REPORT OF CLASSIFICATION OF THE BEST MODEL\".center(80))\n",
    "print(\"-\"*80)\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         📋 TOP 10                                         \n",
      "------------------------------------------------------------------------------------------\n",
      "kernel  penalty      acc    score\n",
      "linear      0.8 0.981132 0.963998\n",
      "linear      0.9 0.981132 0.963998\n",
      "linear      1.0 0.976415 0.965419\n",
      "linear      0.7 0.971698 0.963051\n",
      "linear      0.5 0.966981 0.958314\n",
      "linear      0.6 0.966981 0.960208\n",
      "linear      0.4 0.966981 0.951682\n",
      "linear      0.3 0.962264 0.946471\n",
      "linear      0.2 0.943396 0.933207\n",
      "linear      0.1 0.924528 0.909995\n",
      "------------------------------------------------------------------------------------------\n",
      "                             📈 STATISTICAL SUMMARY BY KERNEL                              \n",
      "------------------------------------------------------------------------------------------\n",
      "             Mean       Std       Min       Max  N° Exps\n",
      "kernel                                                  \n",
      "linear   0.964151  0.017677  0.924528  0.981132       10\n",
      "poly     0.794811  0.052726  0.669811  0.834906       10\n",
      "rbf      0.844811  0.047921  0.740566  0.891509       10\n",
      "sigmoid  0.581132  0.036659  0.542453  0.650943       10\n",
      "Results saved as 'svm_results_full.csv'\n",
      "Best configurations by kernel saved as 'svm_results_best_by_kernel.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_evaluation1_sorted = df_evaluation1.sort_values('acc', ascending=False)\n",
    "df_evaluation1_sorted.to_csv(\n",
    "    'svm_results_full.csv', index=False, encoding='utf-8')\n",
    "best_by_kernel.to_csv('svm_results_best_by_kernel.csv',\n",
    "                      index=False, encoding='utf-8')\n",
    "\n",
    "print(\"📋 TOP 10\".center(90))\n",
    "print(\"-\"*90)\n",
    "print(df_evaluation1_sorted[['kernel', 'penalty', 'acc', 'score']].head(\n",
    "    10).to_string(index=False))\n",
    "print(\"-\"*90)  \n",
    "\n",
    "print(\"📈 STATISTICAL SUMMARY BY KERNEL\".center(90))\n",
    "print(\"-\"*90)\n",
    "stats = df_evaluation1.groupby('kernel')['acc'].agg(\n",
    "    ['mean', 'std', 'min', 'max', 'count'])\n",
    "stats.columns = ['Mean', 'Std', 'Min', 'Max', 'N° Exps']\n",
    "print(stats.to_string())\n",
    "print(\"Results saved as 'svm_results_full.csv'\")\n",
    "print(\"Best configurations by kernel saved as 'svm_results_best_by_kernel.csv'\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with K-Fold Cross-Validation\n",
    "\n",
    "**Improvement 1:** K-Fold CV instead of simple train/test split to:\n",
    "\n",
    "- ✅ Get more reliable performance estimates\n",
    "- ✅ Reduce variance in metrics\n",
    "- ✅ Calculate confidence intervals\n",
    "- ✅ Use **weighted averaging** to handle class imbalance\n",
    "\n",
    "7 classes (Insufficient Weight → Obesity Type III)  \n",
    "10-Fold Cross-Validation  \n",
    "Accuracy, Precision, Recall, F1-Score (weighted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🏆 Final Model Trained with All Dataset\n",
    "\n",
    "**Note:** After evaluating the model with train/test split (above), now we train the final model with **ALL** the data to maximize its predictive capacity. This model is not evaluated because there are no separated test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model:\n",
      "   - Configuration: kernel=linear, C=0.8\n",
      "   - Samples used: 2111 (100% of dataset)\n",
      "   - Classes: 7\n",
      "   - Support vectors: 705\n",
      "\n",
      "Support vectors by class:\n",
      "   Class Insufficient_Weight: 77 vectors (10.9%)\n",
      "   Class Normal_Weight: 141 vectors (20.0%)\n",
      "   Class Obesity_Type_I: 111 vectors (15.7%)\n",
      "   Class Obesity_Type_II: 49 vectors (7.0%)\n",
      "   Class Obesity_Type_III: 9 vectors (1.3%)\n",
      "   Class Overweight_Level_I: 155 vectors (22.0%)\n",
      "   Class Overweight_Level_II: 163 vectors (23.1%)\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "⚠️ This model DOES NOT have valid evaluation metrics\n",
      "   because it was trained with all data (without separated test set).\n",
      "   The metrics reported above (confusion matrix) are correct.\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Model saved as 'svm_final_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Scale dataset\n",
    "scaler_final = StandardScaler()\n",
    "x_scaled_full = scaler_final.fit_transform(x)\n",
    "\n",
    "# Train with the best configuration found\n",
    "final_model = SVC(kernel=best_config['kernel'], C=best_config['penalty'])\n",
    "final_model.fit(x_scaled_full, y.values.ravel())\n",
    "\n",
    "print(f\"\\nModel:\")\n",
    "print(\n",
    "    f\"   - Configuration: kernel={best_config['kernel']}, C={best_config['penalty']}\")\n",
    "print(f\"   - Samples used: {len(x)} (100% of dataset)\")\n",
    "print(f\"   - Classes: {len(final_model.classes_)}\")\n",
    "print(f\"   - Support vectors: {len(final_model.support_)}\")\n",
    "\n",
    "# Distribution of support vectors by class\n",
    "print(f\"\\nSupport vectors by class:\")\n",
    "for i, clase in enumerate(final_model.classes_):\n",
    "    n_sv = final_model.n_support_[i]\n",
    "    print(\n",
    "        f\"   Class {clase}: {n_sv} vectors ({n_sv/len(final_model.support_)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"⚠️ This model DOES NOT have valid evaluation metrics\")\n",
    "print(\"   because it was trained with all data (without separated test set).\")\n",
    "print(\"   The metrics reported above (confusion matrix) are correct.\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "# Guardar el modelo (opcional)\n",
    "with open('svm_final_model.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': final_model, 'scaler': scaler_final,\n",
    "                'config': best_config}, f)\n",
    "print(\"\\nModel saved as 'svm_final_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of SVM using K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_svm_evaluation() defined correctly\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "import time\n",
    "\n",
    "\n",
    "def kfold_svm_evaluation(X, y, kernel='rbf', C=1.0, gamma='scale', degree=3,\n",
    "                         n_folds=10, random_state=42):\n",
    "    \"\"\" \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, dataset features\n",
    "    y : array-like, dataset labels\n",
    "    kernel : str, type of kernel ('linear', 'rbf', 'poly', 'sigmoid')\n",
    "    C : float, regularization parameter\n",
    "    gamma : str or float, kernel coefficient\n",
    "    degree : int, polynomial degree (only for kernel='poly')\n",
    "    n_folds : int, number of folds for cross-validation\n",
    "    random_state : int, seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict with aggregated metrics and results per fold\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Store results\n",
    "    fold_results = []\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    print(f\"Executing {n_folds}-Fold Cross Validation...\")\n",
    "    print(f\"Total samples: {len(X)}\")\n",
    "    print(f\"Kernel: {kernel} | C: {C} | Gamma: {gamma}\")\n",
    "    print(f\"Classes in dataset: {len(np.unique(y))}\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(X), 1):\n",
    "        # Divide data - Use .iloc for positional access (works with DataFrame and array)\n",
    "        if hasattr(X, 'iloc'):  # If DataFrame\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        else:  # If numpy array\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "        if hasattr(y, 'iloc'):  # If Series/DataFrame\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        else:  # If numpy array\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Normalize (IMPORTANT: fit on train, transform on both)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Train\n",
    "        model = SVC(\n",
    "            kernel=kernel,\n",
    "            C=C,\n",
    "            gamma=gamma if kernel != 'linear' else 'scale',\n",
    "            degree=degree if kernel == 'poly' else 3,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # Save for global confusion matrix\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "        # Calculate metrics with WEIGHTED AVERAGING\n",
    "        fold_acc = accuracy_score(y_test, y_pred)\n",
    "        fold_prec = precision_score(\n",
    "            y_test, y_pred, average='weighted', zero_division=0)\n",
    "        fold_rec = recall_score(\n",
    "            y_test, y_pred, average='weighted', zero_division=0)\n",
    "        fold_f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'accuracy': fold_acc,\n",
    "            'precision': fold_prec,\n",
    "            'recall': fold_rec,\n",
    "            'f1_score': fold_f1,\n",
    "            'train_size': len(X_train),\n",
    "            'test_size': len(X_test)\n",
    "        })\n",
    "\n",
    "        print(f\"  FOLD {fold:2d}: Acc={fold_acc:.4f} | Prec={fold_prec:.4f} | \"\n",
    "              f\"Rec={fold_rec:.4f} | F1={fold_f1:.4f}\")\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Calculate aggregated statistics\n",
    "    accuracies = [r['accuracy'] for r in fold_results]\n",
    "    precisions = [r['precision'] for r in fold_results]\n",
    "    recalls = [r['recall'] for r in fold_results]\n",
    "    f1_scores = [r['f1_score'] for r in fold_results]\n",
    "\n",
    "    # Confidence intervals (percentiles 2.5 and 97.5)\n",
    "    ci_95_acc = np.percentile(accuracies, [2.5, 97.5])\n",
    "    ci_95_f1 = np.percentile(f1_scores, [2.5, 97.5])\n",
    "\n",
    "    results = {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_accuracy': np.mean(accuracies),\n",
    "        'std_accuracy': np.std(accuracies),\n",
    "        'mean_precision': np.mean(precisions),\n",
    "        'std_precision': np.std(precisions),\n",
    "        'mean_recall': np.mean(recalls),\n",
    "        'std_recall': np.std(recalls),\n",
    "        'mean_f1': np.mean(f1_scores),\n",
    "        'std_f1': np.std(f1_scores),\n",
    "        'ci_95_accuracy': ci_95_acc,\n",
    "        'ci_95_f1': ci_95_f1,\n",
    "        'training_time': training_time,\n",
    "        'confusion_matrix': confusion_matrix(all_y_true, all_y_pred),\n",
    "        'y_true': np.array(all_y_true),\n",
    "        'y_pred': np.array(all_y_pred)\n",
    "    }\n",
    "\n",
    "    # summary\n",
    "    print(f\"\\n{'-'*70}\")\n",
    "    print(f\"RESULTS ({n_folds}-Fold CV):\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    print(\n",
    "        f\"  Accuracy:  {results['mean_accuracy']:.4f} ± {results['std_accuracy']:.4f}\")\n",
    "    print(\n",
    "        f\"  Precision: {results['mean_precision']:.4f} ± {results['std_precision']:.4f}\")\n",
    "    print(\n",
    "        f\"  Recall:    {results['mean_recall']:.4f} ± {results['std_recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['mean_f1']:.4f} ± {results['std_f1']:.4f}\")\n",
    "    print(f\"\\n  IC 95% Accuracy: [{ci_95_acc[0]:.4f}, {ci_95_acc[1]:.4f}]\")\n",
    "    print(f\"  IC 95% F1-Score: [{ci_95_f1[0]:.4f}, {ci_95_f1[1]:.4f}]\")\n",
    "    print(f\"\\n  Total time: {training_time:.2f}s\")\n",
    "    print(f\"{'-'*70}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"kfold_svm_evaluation() defined correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all kernels\n",
    "\n",
    "Test the 4 kernels with default parameters (C=1.0, gamma='scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "# TESTING KERNEL: LINEAR\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Executing 10-Fold Cross Validation...\n",
      "Total samples: 2111\n",
      "Kernel: linear | C: 1.0 | Gamma: scale\n",
      "Classes in dataset: 7\n",
      "\n",
      "  FOLD  1: Acc=0.9528 | Prec=0.9591 | Rec=0.9528 | F1=0.9528\n",
      "  FOLD  2: Acc=0.9810 | Prec=0.9820 | Rec=0.9810 | F1=0.9811\n",
      "  FOLD  3: Acc=0.9336 | Prec=0.9383 | Rec=0.9336 | F1=0.9330\n",
      "  FOLD  4: Acc=0.9431 | Prec=0.9486 | Rec=0.9431 | F1=0.9440\n",
      "  FOLD  5: Acc=0.9621 | Prec=0.9629 | Rec=0.9621 | F1=0.9619\n",
      "  FOLD  6: Acc=0.9431 | Prec=0.9458 | Rec=0.9431 | F1=0.9432\n",
      "  FOLD  7: Acc=0.9289 | Prec=0.9340 | Rec=0.9289 | F1=0.9281\n",
      "  FOLD  8: Acc=0.9431 | Prec=0.9440 | Rec=0.9431 | F1=0.9432\n",
      "  FOLD  9: Acc=0.9526 | Prec=0.9534 | Rec=0.9526 | F1=0.9518\n",
      "  FOLD 10: Acc=0.9810 | Prec=0.9815 | Rec=0.9810 | F1=0.9809\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTS (10-Fold CV):\n",
      "----------------------------------------------------------------------\n",
      "  Accuracy:  0.9522 ± 0.0170\n",
      "  Precision: 0.9550 ± 0.0158\n",
      "  Recall:    0.9522 ± 0.0170\n",
      "  F1-Score:  0.9520 ± 0.0171\n",
      "\n",
      "  IC 95% Accuracy: [0.9300, 0.9810]\n",
      "  IC 95% F1-Score: [0.9292, 0.9811]\n",
      "\n",
      "  Total time: 0.63s\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "# TESTING KERNEL: RBF\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Executing 10-Fold Cross Validation...\n",
      "Total samples: 2111\n",
      "Kernel: rbf | C: 1.0 | Gamma: scale\n",
      "Classes in dataset: 7\n",
      "\n",
      "  FOLD  1: Acc=0.8868 | Prec=0.8949 | Rec=0.8868 | F1=0.8878\n",
      "  FOLD  2: Acc=0.9100 | Prec=0.9160 | Rec=0.9100 | F1=0.9111\n",
      "  FOLD  3: Acc=0.8720 | Prec=0.8852 | Rec=0.8720 | F1=0.8753\n",
      "  FOLD  4: Acc=0.9194 | Prec=0.9234 | Rec=0.9194 | F1=0.9196\n",
      "  FOLD  5: Acc=0.8957 | Prec=0.9084 | Rec=0.8957 | F1=0.8981\n",
      "  FOLD  6: Acc=0.8768 | Prec=0.8842 | Rec=0.8768 | F1=0.8783\n",
      "  FOLD  7: Acc=0.8626 | Prec=0.8615 | Rec=0.8626 | F1=0.8611\n",
      "  FOLD  8: Acc=0.8531 | Prec=0.8715 | Rec=0.8531 | F1=0.8562\n",
      "  FOLD  9: Acc=0.9052 | Prec=0.9074 | Rec=0.9052 | F1=0.9058\n",
      "  FOLD 10: Acc=0.9479 | Prec=0.9498 | Rec=0.9479 | F1=0.9483\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTS (10-Fold CV):\n",
      "----------------------------------------------------------------------\n",
      "  Accuracy:  0.8929 ± 0.0272\n",
      "  Precision: 0.9002 ± 0.0249\n",
      "  Recall:    0.8929 ± 0.0272\n",
      "  F1-Score:  0.8942 ± 0.0268\n",
      "\n",
      "  IC 95% Accuracy: [0.8552, 0.9415]\n",
      "  IC 95% F1-Score: [0.8573, 0.9418]\n",
      "\n",
      "  Total time: 1.07s\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "# TESTING KERNEL: POLY\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Executing 10-Fold Cross Validation...\n",
      "Total samples: 2111\n",
      "Kernel: poly | C: 1.0 | Gamma: scale\n",
      "Classes in dataset: 7\n",
      "\n",
      "  FOLD  1: Acc=0.8302 | Prec=0.8333 | Rec=0.8302 | F1=0.8277\n",
      "  FOLD  2: Acc=0.8483 | Prec=0.8505 | Rec=0.8483 | F1=0.8460\n",
      "  FOLD  3: Acc=0.8104 | Prec=0.8166 | Rec=0.8104 | F1=0.8099\n",
      "  FOLD  4: Acc=0.8152 | Prec=0.8378 | Rec=0.8152 | F1=0.8092\n",
      "  FOLD  5: Acc=0.8720 | Prec=0.8785 | Rec=0.8720 | F1=0.8730\n",
      "  FOLD  6: Acc=0.8294 | Prec=0.8255 | Rec=0.8294 | F1=0.8233\n",
      "  FOLD  7: Acc=0.8294 | Prec=0.8280 | Rec=0.8294 | F1=0.8253\n",
      "  FOLD  8: Acc=0.8152 | Prec=0.8142 | Rec=0.8152 | F1=0.8101\n",
      "  FOLD  9: Acc=0.8531 | Prec=0.8555 | Rec=0.8531 | F1=0.8490\n",
      "  FOLD 10: Acc=0.8910 | Prec=0.8948 | Rec=0.8910 | F1=0.8878\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTS (10-Fold CV):\n",
      "----------------------------------------------------------------------\n",
      "  Accuracy:  0.8394 ± 0.0251\n",
      "  Precision: 0.8435 ± 0.0252\n",
      "  Recall:    0.8394 ± 0.0251\n",
      "  F1-Score:  0.8361 ± 0.0260\n",
      "\n",
      "  IC 95% Accuracy: [0.8115, 0.8867]\n",
      "  IC 95% F1-Score: [0.8093, 0.8845]\n",
      "\n",
      "  Total time: 0.97s\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "# TESTING KERNEL: SIGMOID\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Executing 10-Fold Cross Validation...\n",
      "Total samples: 2111\n",
      "Kernel: sigmoid | C: 1.0 | Gamma: scale\n",
      "Classes in dataset: 7\n",
      "\n",
      "  FOLD  1: Acc=0.5755 | Prec=0.5781 | Rec=0.5755 | F1=0.5758\n",
      "  FOLD  2: Acc=0.5687 | Prec=0.5629 | Rec=0.5687 | F1=0.5627\n",
      "  FOLD  3: Acc=0.5735 | Prec=0.5872 | Rec=0.5735 | F1=0.5786\n",
      "  FOLD  4: Acc=0.6303 | Prec=0.6341 | Rec=0.6303 | F1=0.6291\n",
      "  FOLD  5: Acc=0.5545 | Prec=0.5835 | Rec=0.5545 | F1=0.5615\n",
      "  FOLD  6: Acc=0.5403 | Prec=0.5463 | Rec=0.5403 | F1=0.5405\n",
      "  FOLD  7: Acc=0.5403 | Prec=0.5417 | Rec=0.5403 | F1=0.5394\n",
      "  FOLD  8: Acc=0.5640 | Prec=0.5703 | Rec=0.5640 | F1=0.5617\n",
      "  FOLD  9: Acc=0.6493 | Prec=0.6562 | Rec=0.6493 | F1=0.6510\n",
      "  FOLD 10: Acc=0.6066 | Prec=0.6228 | Rec=0.6066 | F1=0.6127\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTS (10-Fold CV):\n",
      "----------------------------------------------------------------------\n",
      "  Accuracy:  0.5803 ± 0.0351\n",
      "  Precision: 0.5883 ± 0.0359\n",
      "  Recall:    0.5803 ± 0.0351\n",
      "  F1-Score:  0.5813 ± 0.0356\n",
      "\n",
      "  IC 95% Accuracy: [0.5403, 0.6450]\n",
      "  IC 95% F1-Score: [0.5397, 0.6461]\n",
      "\n",
      "  Total time: 0.87s\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "SUMMARY\n",
      "------------------------------------------------------------------------------------------\n",
      " experiment_id  kernel   C gamma degree  mean_accuracy  std_accuracy  mean_f1   std_f1  ci_95_acc_lower  ci_95_acc_upper  training_time\n",
      "             1  linear 1.0 scale      -       0.952155      0.017016 0.952017 0.017124         0.929976         0.981043       0.633119\n",
      "             2     rbf 1.0 scale      -       0.892945      0.027229 0.894156 0.026828         0.855213         0.941469       1.066475\n",
      "             3    poly 1.0 scale      3       0.839417      0.025088 0.836129 0.025960         0.811493         0.886730       0.967782\n",
      "             4 sigmoid 1.0 scale      -       0.580296      0.035064 0.581311 0.035636         0.540284         0.645024       0.870296\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " BEST KERNEL: LINEAR\n",
      "   Accuracy: 0.9522 ± 0.0170\n",
      "   F1-Score: 0.9520 ± 0.0171\n",
      "   IC 95%: [0.9300, 0.9810]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "\n",
    "experiments_log = [] \n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f\"\\n{'-'*70}\")\n",
    "    print(f\"# TESTING KERNEL: {kernel.upper()}\")\n",
    "    print(f\"{'-'*70}\\n\")\n",
    "\n",
    "    results = kfold_svm_evaluation(\n",
    "        X=x,  \n",
    "        y=y.values.ravel(),  # Convert y to 1D array\n",
    "        kernel=kernel,\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        degree=3,  \n",
    "        n_folds=10,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    experiments_log.append({\n",
    "        'experiment_id': len(experiments_log) + 1,\n",
    "        'kernel': kernel,\n",
    "        'C': 1.0,\n",
    "        'gamma': 'scale',\n",
    "        'degree': 3 if kernel == 'poly' else '-',\n",
    "        'mean_accuracy': results['mean_accuracy'],\n",
    "        'std_accuracy': results['std_accuracy'],\n",
    "        'mean_f1': results['mean_f1'],\n",
    "        'std_f1': results['std_f1'],\n",
    "        'ci_95_acc_lower': results['ci_95_accuracy'][0],\n",
    "        'ci_95_acc_upper': results['ci_95_accuracy'][1],\n",
    "        'training_time': results['training_time']\n",
    "    })\n",
    "\n",
    "# DataFrame with all results\n",
    "df_experiments = pd.DataFrame(experiments_log)\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"SUMMARY\")\n",
    "print(\"-\"*90)\n",
    "print(df_experiments.to_string(index=False))\n",
    "print(\"-\"*90) \n",
    "\n",
    "best_exp = df_experiments.loc[df_experiments['mean_accuracy'].idxmax()]\n",
    "print(f\"\\n BEST KERNEL: {best_exp['kernel'].upper()}\")\n",
    "print(\n",
    "    f\"   Accuracy: {best_exp['mean_accuracy']:.4f} ± {best_exp['std_accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {best_exp['mean_f1']:.4f} ± {best_exp['std_f1']:.4f}\")\n",
    "print(\n",
    "    f\"   IC 95%: [{best_exp['ci_95_acc_lower']:.4f}, {best_exp['ci_95_acc_upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results as CVS file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as 'svm_kfold_experiments.csv'\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "SUMMARY\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Evaluation Strategy: 10-Fold Cross-Validation\n",
      "- Method: K-Fold with shuffle\n",
      "- Folds: 10\n",
      "- Random State: 42\n",
      "- Metrics: Weighted averaging (handles imbalance)\n",
      "\n",
      "Kernels:\n",
      "\n",
      "1. LINEAR   | Acc: 0.9522±0.0170 | F1: 0.9520±0.0171 | Time: 0.63s\n",
      "2. RBF      | Acc: 0.8929±0.0272 | F1: 0.8942±0.0268 | Time: 1.07s\n",
      "3. POLY     | Acc: 0.8394±0.0251 | F1: 0.8361±0.0260 | Time: 0.97s\n",
      "4. SIGMOID  | Acc: 0.5803±0.0351 | F1: 0.5813±0.0356 | Time: 0.87s\n",
      "\n",
      "BEST CONFIGURATION:\n",
      "   Kernel: LINEAR\n",
      "   Accuracy: 0.9522 ± 0.0170\n",
      "   IC 95%: [0.9300, 0.9810]\n",
      "   F1-Score: 0.9520 ± 0.0171\n",
      "   Tiempo: 0.63s\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_experiments.to_csv('svm_kfold_experiments.csv',\n",
    "                      index=False, encoding='utf-8')\n",
    "print(\"Results saved as 'svm_kfold_experiments.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"SUMMARY\")\n",
    "print(\"-\"*90)\n",
    "print(f\"\"\"\n",
    "Evaluation Strategy: 10-Fold Cross-Validation\n",
    "- Method: K-Fold with shuffle\n",
    "- Folds: 10\n",
    "- Random State: 42\n",
    "- Metrics: Weighted averaging (handles imbalance)\n",
    "\n",
    "Kernels:\n",
    "\"\"\")\n",
    "\n",
    "for idx, row in df_experiments.iterrows():\n",
    "    print(f\"{idx+1}. {row['kernel'].upper():8s} | \"\n",
    "          f\"Acc: {row['mean_accuracy']:.4f}±{row['std_accuracy']:.4f} | \"\n",
    "          f\"F1: {row['mean_f1']:.4f}±{row['std_f1']:.4f} | \"\n",
    "          f\"Time: {row['training_time']:.2f}s\")\n",
    "\n",
    "print(f\"\\nBEST CONFIGURATION:\")\n",
    "print(f\"   Kernel: {best_exp['kernel'].upper()}\")\n",
    "print(\n",
    "    f\"   Accuracy: {best_exp['mean_accuracy']:.4f} ± {best_exp['std_accuracy']:.4f}\")\n",
    "print(\n",
    "    f\"   IC 95%: [{best_exp['ci_95_acc_lower']:.4f}, {best_exp['ci_95_acc_upper']:.4f}]\")\n",
    "print(f\"   F1-Score: {best_exp['mean_f1']:.4f} ± {best_exp['std_f1']:.4f}\")\n",
    "print(f\"   Tiempo: {best_exp['training_time']:.2f}s\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold CV vs Train/Test Split\n",
    "\n",
    "**1. More reliable estimation**\n",
    "\n",
    "- K-Fold uses **all data** for training and validation\n",
    "- Reduces **variance** in metrics\n",
    "- Train/Test depends on ONE random split\n",
    "\n",
    "**2. Confidence intervals**\n",
    "\n",
    "- K-Fold provides **10 independent measurements**\n",
    "- We calculate **95% CI** to quantify uncertainty\n",
    "- Train/Test only gives **1 value** without confidence measure\n",
    "\n",
    "**3. Weighted metrics**\n",
    "\n",
    "- We use `average='weighted'` in all metrics\n",
    "- Handles correctly dataset with **7 unbalanced classes**\n",
    "- Avoids artificially high accuracy by predicting majority class\n",
    "\n",
    "**4. Correct normalization**\n",
    "\n",
    "- StandardScaler **fit in train, transform in test** in each fold\n",
    "- Prevents **data leakage**\n",
    "- Simulates correctly unseen data\n",
    "\n",
    "**5. Reproducibility**\n",
    "\n",
    "- `random_state=42` fixed in all experiments\n",
    "- Results **reproducible** for comparison\n",
    "- Important for scientific validation\n",
    "\n",
    "### 📊 **Interpretation of Results**\n",
    "\n",
    "**Standard Deviation (±std)**\n",
    "\n",
    "- Low std → Model is **robust** and **stable**\n",
    "- High std → Model is **sensitive** to data splits\n",
    "\n",
    "**95% Confidence Interval**\n",
    "\n",
    "- Range where we expect 95% of future results\n",
    "- Narrow → Higher **certainty** in performance\n",
    "- Wide → Higher **variability**, less confidence\n",
    "\n",
    "**F1-Score Weighted**\n",
    "\n",
    "- Most important metric for **imbalanced data**\n",
    "- Balances precision and recall by class\n",
    "- Accuracy may be misleading in imbalance\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4751341,
     "sourceId": 8055891,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
